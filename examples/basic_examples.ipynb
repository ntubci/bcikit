{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook showcase how we can load an EEG dataset, and perform preprocessing. We train the EEGNet model with leave one subject paradigm and k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\github\\bcikit\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"seed\": 12,\n",
    "  \"segment_config\": {\n",
    "    \"window_len\": 1,\n",
    "    \"shift_len\": 250,\n",
    "    \"sample_rate\": 250,\n",
    "  },\n",
    "  \"bandpass_config\": {\n",
    "      \"sample_rate\": 250,\n",
    "      \"lowcut\": 7,\n",
    "      \"highcut\": 70,\n",
    "      \"order\": 6\n",
    "  },\n",
    "  \"subject_ids\": {\n",
    "    \"low\": 1,\n",
    "    \"high\": 10\n",
    "  },\n",
    "  \"root\": \"../data/hsssvep\",\n",
    "  \"selected_channels\": ['PZ', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'O1', 'Oz', 'O2', 'PO7', 'PO8'],\n",
    "  \"batchsize\": 64,\n",
    "  \"num_classes\": 40,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcikit.transforms.channels import pick_channels\n",
    "from bcikit.transforms.segment_time import segment_data_time_domain\n",
    "from bcikit.transforms.bandpass import butter_bandpass_filter\n",
    "\n",
    "\n",
    "def preprocessing(data, targets, channel_names, sample_rate, selected_channels, segment_config, bandpass_config, verbose, **kwargs):\n",
    "    print()\n",
    "    print(\"preprocessing data shape\", data.shape) # (subject,session,trial,channel,time)\n",
    "\n",
    "    # filter channels\n",
    "    data = pick_channels(\n",
    "        data=data, \n",
    "        channel_names=channel_names, \n",
    "        selected_channels=selected_channels,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(\"after pick_channels\", data.shape)\n",
    "\n",
    "    # segment signal and select the first segment\n",
    "    data = segment_data_time_domain(\n",
    "        data=data,\n",
    "        window_len=segment_config['window_len'],\n",
    "        shift_len=segment_config['shift_len'],\n",
    "        sample_rate=segment_config['sample_rate'],\n",
    "        add_segment_axis=True,\n",
    "    )\n",
    "    data = data[:, :, :, :, 0, :] # select the first segment, and remove the rest\n",
    "    print(\"after segment_data_time_domain\", data.shape)\n",
    "\n",
    "    # bandpass filter\n",
    "    data = butter_bandpass_filter(\n",
    "        signal=data, \n",
    "        lowcut=bandpass_config[\"lowcut\"], \n",
    "        highcut=bandpass_config[\"highcut\"], \n",
    "        sample_rate=bandpass_config[\"sample_rate\"], \n",
    "        order=bandpass_config[\"order\"]\n",
    "    )\n",
    "    print(\"after butter_bandpass_filter\", data.shape)\n",
    "\n",
    "    # since we are doing leave one subject out, we don't care about `session`, we only want data in this format (subject, trial, channel, time).\n",
    "    data = data.reshape((data.shape[0], data.shape[1]*data.shape[2], data.shape[3], data.shape[4]))\n",
    "    targets = targets.reshape((targets.shape[0], targets.shape[1]*targets.shape[2]))\n",
    "\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load subject IDs [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Load subject: 1\n",
      "Load subject: 2\n",
      "Load subject: 3\n",
      "Load subject: 4\n",
      "Load subject: 5\n",
      "Load subject: 6\n",
      "Load subject: 7\n",
      "Load subject: 8\n",
      "Load subject: 9\n",
      "Load subject: 10\n",
      "\n",
      "preprocessing data shape (10, 1, 240, 64, 1000)\n",
      "after pick_channels (10, 1, 240, 11, 1000)\n",
      "after segment_data_time_domain (10, 1, 240, 11, 250)\n",
      "after butter_bandpass_filter (10, 1, 240, 11, 250)\n",
      "\n",
      "train_loader: (1440, 11, 250) (1440,)\n",
      "val_loader: (720, 11, 250) (720,)\n",
      "test_loader: (240, 11, 250) (240,)\n"
     ]
    }
   ],
   "source": [
    "from bcikit.datasets.ssvep import HSSSVEP\n",
    "from bcikit.datasets import EEGDataloader\n",
    "from bcikit.datasets.data_selection_methods import leave_one_subject_out\n",
    "\n",
    "\n",
    "subject_ids = list(np.arange(config['subject_ids']['low'], config['subject_ids']['high']+1, dtype=int))\n",
    "print(\"Load subject IDs\", subject_ids)\n",
    "\n",
    "data = EEGDataloader(\n",
    "    dataset=HSSSVEP, \n",
    "    root=config[\"root\"], \n",
    "    subject_ids=subject_ids,\n",
    "    preprocessing_fn=preprocessing, # customize your own preprocessing\n",
    "    data_selection_fn=leave_one_subject_out, # customize your data selection function or use common ones from `data_selection_methods`\n",
    "    verbose=True,\n",
    "    selected_channels=config[\"selected_channels\"],\n",
    "    segment_config=config[\"segment_config\"],\n",
    "    bandpass_config=config[\"bandpass_config\"],\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = data.get_dataloaders(test_subject_id=1, batchsize=64)\n",
    "\n",
    "print()\n",
    "print(\"train_loader:\", train_loader.dataset.data.shape, train_loader.dataset.targets.shape)\n",
    "print(\"val_loader:\", val_loader.dataset.data.shape, val_loader.dataset.targets.shape)\n",
    "print(\"test_loader:\", test_loader.dataset.data.shape, test_loader.dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([16, 11, 250])\n",
      "Output shape: torch.Size([16, 40])\n",
      "Model size: 63496\n"
     ]
    }
   ],
   "source": [
    "from bcikit.models import CompactEEGNet\n",
    "from bcikit.models.utils import count_params\n",
    "\n",
    "\n",
    "model = CompactEEGNet(\n",
    "    num_channel=len(config['selected_channels']),\n",
    "    num_classes=config['num_classes'],\n",
    "    signal_length=config['segment_config']['window_len'] * config['bandpass_config']['sample_rate'],\n",
    ").to(device)\n",
    "\n",
    "x = torch.ones((16, len(config['selected_channels']), config['segment_config']['window_len']*config['bandpass_config']['sample_rate'])).to(device)\n",
    "y = model(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", y.shape)\n",
    "print('Model size:', count_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "optimizer = optim.Adam(params_to_update, lr=learning_rate, weight_decay=0.05)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 85.87423\n",
      "Epoch 1 loss: 81.52420\n",
      "Epoch 2 loss: 72.76737\n",
      "Epoch 3 loss: 62.58075\n",
      "Epoch 4 loss: 54.42659\n",
      "Epoch 5 loss: 47.62129\n",
      "Epoch 6 loss: 45.38964\n",
      "Epoch 7 loss: 45.18582\n",
      "Epoch 8 loss: 41.74949\n",
      "Epoch 9 loss: 44.05182\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for X, Y in train_loader:\n",
    "        inputs = X.to(device)\n",
    "        labels = Y.long().to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch {} loss: {:.5f}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
